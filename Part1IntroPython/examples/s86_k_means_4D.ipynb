{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=pd.read_csv(\"data_files\\\\iris_dataset_no_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iris.sepal_length,iris.petal_width,'o')\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means\n",
    "\n",
    "The idea is to find $K$ groups of observations (clusters), denoted by $C_k$, which are similar to one another. The mathematical objective is to partition observations into $K$ sets so as to minimize the within-cluster sum of squares:\n",
    "\n",
    "$$ Minimize \\displaystyle \\sum_{k=1}^K \\sum_{\\mathrm{x}_n \\in C_k} ||\\mathrm{x}_n - \\mu_k ||^2 with \\ respect \\ to \\ \\displaystyle C_k, \\ \\mu_k$$\n",
    "\n",
    "where $\\mu_k$ is the mean point of $C_k$, and is referred to as *centroid*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach: Iterative Refinement (Lloyd's algorithm)\n",
    "\n",
    "- Step 0: Start with an initial guess of a set of centroids $\\mu_k$.\n",
    "- Step 1: Create clusters containing points closest in distance to each centroid\n",
    "- Step 2: Update the centroids as the means of all points in each cluster.\n",
    "- Step 3: Repeat 1 and 2 until the assignments of clusters and centroids does not change (or max number of steps reached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a random starting point (i.e., generate a uniform random number for each dimension of data)\n",
    "data=np.array(iris)\n",
    "mins=data.min(axis=0)\n",
    "maxs=data.max(axis=0)\n",
    "print([np.random.uniform(low=x[0],high=x[1]) for x in zip(mins,maxs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=2 #Number of clusters\n",
    "\n",
    "#Step 0: Initial Guess\n",
    "mu0= [[np.random.uniform(low=x[0],high=x[1]) for x in zip(mins,maxs)] for i in range(K)] \n",
    "  \n",
    "print(\"Initial Guess\",mu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['Cluster']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get one data point (i.e., row) from the dataframe\n",
    "rel_cols=['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "iris.loc[1,rel_cols].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Create clusters containing points closest in distance to each centroid\n",
    "\n",
    "for index,row in iris.iterrows():\n",
    "    \n",
    "    p= np.array(row[rel_cols])\n",
    "    d=np.array([np.linalg.norm(p-mu0[k]) for k in range(K)])\n",
    "    bestKindex=np.argmin(d)\n",
    "    iris.Cluster.loc[index]=bestKindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(x_vars=rel_cols, y_vars=rel_cols, data=iris, hue=\"Cluster\", size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get averages for each column for cluster 0\n",
    "[iris[col][iris.Cluster==0].mean() for col in rel_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Update the centroids as the means of all points in each cluster.\n",
    "\n",
    "mu1= [np.array([iris[col][iris.Cluster==k].mean() for col in rel_cols]) for k in range(K)] \n",
    "\n",
    "print(\"Updated Guess:\",mu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it all together\n",
    "\n",
    "diff=sum([np.linalg.norm(mu1[k]-mu0[k]) for k in range(K)])\n",
    "n=2\n",
    "nmax=100\n",
    "\n",
    "while diff>.00001 and n<nmax:\n",
    "    print(\"Iteration:\",n)\n",
    "    n+=1\n",
    "    \n",
    "    mu0=mu1\n",
    "    \n",
    "    for index,row in iris.iterrows():\n",
    "\n",
    "        p= np.array(row[rel_cols])\n",
    "        d=np.array([np.linalg.norm(p-mu0[k]) for k in range(K)])\n",
    "        bestKindex=np.argmin(d)\n",
    "        iris.Cluster.loc[index]=bestKindex\n",
    "    \n",
    "    sns.pairplot(x_vars=rel_cols, y_vars=rel_cols, data=iris, hue=\"Cluster\", size=5)\n",
    "    \n",
    "    mu1= [np.array([iris[col][iris.Cluster==k].mean() for col in rel_cols]) for k in range(K)] \n",
    "    \n",
    "    print(\"Updated Guess\",mu1)\n",
    "    diff=sum([np.linalg.norm(mu1[k]-mu0[k]) for k in range(K)])\n",
    "    print(\"diff=\",diff)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster Centers:\", mu1)\n",
    "print(iris.Cluster.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using other libraries\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Determining number of clusters\n",
    "nClusters=range(2,10)\n",
    "sumDistances=[]\n",
    "for n in nClusters:\n",
    "    kmeans=KMeans(n_clusters=n).fit(iris[rel_cols])\n",
    "    sumDistances.append(kmeans.inertia_) #Proxy for SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nClusters,sumDistances,'-')\n",
    "plt.xlabel('nClusters')\n",
    "plt.ylabel('Sum Of Distances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=3).fit(iris)\n",
    "iris['Cluster']=kmeans.labels_\n",
    "g = sns.pairplot(iris,hue='Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisNames=pd.read_csv(\"iris_dataset.csv\")\n",
    "irisNames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(irisNames,hue='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(iris.Cluster,irisNames.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
